# General Parameters, see comment for each definition
# choose the tree booster, 0: tree, 1: linear
booster_type = 0 
# choose logistic regression loss function for binary classification
objective = binary:logistic

# Tree Booster Parameters
# step size shrinkage
#bst:eta = 0.1 
# minimum loss reduction required to make a further partition
#bst:gamma = 0.1
# minimum sum of instance weight(hessian) needed in a child
bst:min_child_weight = 1 
# maximum depth of a tree
#bst:max_depth = 6
bst:subsample = 0.5

# Task Parameters
# the number of round to do boosting
#num_round = 100
# 0 means do not save any model except the final round model
save_period = 0 
# The path of training data
#data = "..." 
# The path of validation data, used to monitor training process, here [test] sets name of the validation set
#eval[test] = "..." 
# evaluate on training data as well each round
eval_train = 1
# The path of test data 
#test:data = "..."      

#model_in = "..."
#model_out = "..."
#model_dir = "..."

eval_metric=negllik
nthread=6
